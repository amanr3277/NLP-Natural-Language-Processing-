{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEfjR4ZPNSJS",
        "outputId": "cc3ead96-2f57-4364-cfb0-b360b6d2ba7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Embedding Techniques using Embedding Layer in Keras**"
      ],
      "metadata": {
        "id": "rau5G3YdNcQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "RW-QlVOGN3XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OP5tfvZOrr5",
        "outputId": "a1a6dcca-ff98-495b-e1b6-a9ac1b91f37b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent=[\"the glass of milk\",\n",
        "      \"the glass of juice\",\n",
        "      \"the cup of tea\",\n",
        "      \"I am a good boy\",\n",
        "      \"I am a good devloper\",\n",
        "      \"understand the meaning of words\",\n",
        "      \"your videos are good\"]"
      ],
      "metadata": {
        "id": "t38UVC1xQNb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0YdwozBRJAo",
        "outputId": "7cc908d9-7b6a-45cb-c87f-0c7a9ab6a8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good devloper',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Vocubulary size\n",
        "voc_size=500"
      ],
      "metadata": {
        "id": "8xhoGFHMRLXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OaXh_3q9RTTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Representation**"
      ],
      "metadata": {
        "id": "1rA_9vMMRUek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repr=[one_hot(words, voc_size) for words in sent]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsjfjqdRaHP",
        "outputId": "4437c53b-d334-4af6-e0a1-719ca0a28f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[384, 183, 340, 43], [384, 183, 340, 166], [384, 53, 340, 98], [386, 358, 87, 175, 328], [386, 358, 87, 175, 177], [32, 384, 15, 340, 115], [440, 118, 60, 175]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "CkvuJmxPRqF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pre paddding\n",
        "sent_length=8\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QttQeVrGVP8z",
        "outputId": "4823bd7a-c498-428e-c1e2-3a030fde2a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0 384 183 340  43]\n",
            " [  0   0   0   0 384 183 340 166]\n",
            " [  0   0   0   0 384  53 340  98]\n",
            " [  0   0   0 386 358  87 175 328]\n",
            " [  0   0   0 386 358  87 175 177]\n",
            " [  0   0   0  32 384  15 340 115]\n",
            " [  0   0   0   0 440 118  60 175]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 10 feature dimensions\n",
        "dim=10"
      ],
      "metadata": {
        "id": "MQZp9u4eWRsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "id": "T7_lJNB8Wd71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WctUXSmxWyYA",
        "outputId": "33635fe0-4bd5-4a0c-fe4c-6d597d4540cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             5000      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5000 (19.53 KB)\n",
            "Trainable params: 5000 (19.53 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 'the glass of milk,\n",
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWZ_jv_iZMO0",
        "outputId": "d16096a3-5aa2-4d16-9498-0f87bc2dd277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0, 384, 183, 340,  43], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMviKjk5ZVsH",
        "outputId": "478cf024-01e2-4c51-db19-4ead39027168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 105ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04382252,  0.02489794,  0.04069808, -0.0092678 ,  0.02741071,\n",
              "         0.03469196,  0.04815098, -0.02835548,  0.03046911,  0.01331208],\n",
              "       [ 0.04382252,  0.02489794,  0.04069808, -0.0092678 ,  0.02741071,\n",
              "         0.03469196,  0.04815098, -0.02835548,  0.03046911,  0.01331208],\n",
              "       [ 0.04382252,  0.02489794,  0.04069808, -0.0092678 ,  0.02741071,\n",
              "         0.03469196,  0.04815098, -0.02835548,  0.03046911,  0.01331208],\n",
              "       [ 0.04382252,  0.02489794,  0.04069808, -0.0092678 ,  0.02741071,\n",
              "         0.03469196,  0.04815098, -0.02835548,  0.03046911,  0.01331208],\n",
              "       [ 0.01227101, -0.0394947 , -0.00966777, -0.01316142,  0.01606849,\n",
              "        -0.04887921, -0.01261168, -0.01865089,  0.03273659,  0.02365435],\n",
              "       [ 0.02673805,  0.0360315 ,  0.01992315,  0.03068899, -0.03489194,\n",
              "        -0.03445292, -0.03620588,  0.00055482,  0.00106256,  0.0095722 ],\n",
              "       [ 0.01079465, -0.04775337,  0.03583357,  0.02685031, -0.00366639,\n",
              "         0.01373849,  0.04680859, -0.03976976, -0.03682792, -0.01067009],\n",
              "       [ 0.0383651 ,  0.03207311, -0.00590258, -0.00133052,  0.02227088,\n",
              "         0.03379165, -0.00097694, -0.01382096,  0.03408606,  0.04165446]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cnBRD9m7ZiXM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}